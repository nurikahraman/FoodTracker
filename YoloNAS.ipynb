{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMW6XgXOUM2lgdXHYUyHdOt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurikahraman/FoodTracker/blob/main/YoloNAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utS7MBd0QOtP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p '/content/dataset/val'\n",
        "!mkdir -p '/content/dataset/train'\n",
        "\n",
        "#Datasets (This gets downloaded in \"/content/foodChallenge/data\")\n",
        "!echo \"üóÑ Preparing the validation dataset...\"\n",
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/content/FoodRecognitionChallenge/val.zip\" -d \"/content/dataset/val\"\n",
        "\n",
        "!echo \"üóÑ Preparing the dataset for training...\"\n",
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/content/FoodRecognitionChallenge/train.zip\" -d \"/content/dataset/train\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install super-gradients"
      ],
      "metadata": {
        "id": "AjRAiamXZJtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050\n",
        "from super_gradients.training import Trainer, dataloaders, models\n",
        "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
        "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtpvgHlfZi_5",
        "outputId": "df65281c-1ed9-408b-c027-2ee15f509327"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-29 19:49:30] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-29 19:49:39] INFO - utils.py - NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    #eƒüitim parametreleri\n",
        "    CHECKPOINT_DIR = '/content/drive/MyDrive/Colab Notebooks/Aptal Buzdolabƒ±/outputs'# checkpoint klas√∂r√ºn√ºn tam yolu (absolute path)\n",
        "    EXPERIMENT_NAME = 'Aptal Buzdolabƒ±' # eƒüitim s√ºrecine verdiƒüimiz isim\n",
        "\n",
        "    #veri seti parametreleri\n",
        "    DATA_DIR = '/content/dataset/' # veri setinin bulunduƒüu ana klas√∂r\n",
        "\n",
        "    TRAIN_IMAGES_DIR = 'train/images' # DATA_DIR i√ßinde eƒüitim verilerinin bulunduƒüu klas√∂r√ºn yolu\n",
        "    TRAIN_LABELS_DIR = 'train' # DATA_DIR i√ßinde eƒüitim verilerinin etiketlerinin bulunduƒüu klas√∂r√ºn yolu\n",
        "\n",
        "    VAL_IMAGES_DIR = 'val/images' # DATA_DIR i√ßinde validasyon verilerinin bulunduƒüu klas√∂r√ºn yolu\n",
        "    VAL_LABELS_DIR = 'val' # DATA_DIR i√ßinde validasyon verilerinin etiketlerinin  bulunduƒüu klas√∂r√ºn yolu\n",
        "\n",
        "    #TEST_IMAGES_DIR = 'test/images' # DATA_DIR i√ßinde test verilerinin bulunduƒüu klas√∂r√ºn yolu\n",
        "    #TEST_LABELS_DIR = 'test/labels' # DATA_DIR i√ßinde test verilerinin etiketlerinin  bulunduƒüu klas√∂r√ºn yolu\n",
        "    CLASSES = ['food'] # sƒ±nƒ±flarƒ±n isimleri.\n",
        "\n",
        "    NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "    #ver-y√ºkleyici (dataloader) parametreleri\n",
        "    DATALOADER_PARAMS = {\n",
        "      'batch_size':16,\n",
        "      'num_workers':2\n",
        "    }\n",
        "\n",
        "    # model parametreleri\n",
        "    MODEL_NAME = 'yolo_nas_l' # yolo_nas_s, yolo_nas_m, yolo_nas_l arasƒ±ndan birini se√ßiyoruz\n",
        "    PRETRAINED_WEIGHTS = 'coco' # burada tek se√ßenek var: 'coco'\n",
        "\n",
        "#from pycocotools.coco import COCO\n",
        "#class Paths:\n",
        "#  DATASET_DIR = \"/content/dataset/\"\n",
        "#  TRAIN_DATA_DIR = f\"{DATASET_DIR}train/\"\n",
        "#  TRAIN_IMAGES_DIR = f\"{TRAIN_DATA_DIR}images/\"\n",
        "#  TRAIN_ANNOTATIONS = f\"{TRAIN_DATA_DIR}annotations.json\"\n",
        "#  VAL_DATA_DIR = f\"{DATASET_DIR}val/\"\n",
        "#  VAL_ANNOTATIONS = f\"{VAL_DATA_DIR}annotations.json\"\n",
        "#  VAL_IMAGES_DIR = f\"{VAL_DATA_DIR}images/\"\n",
        "\n",
        "\n",
        "#class DatasetLabels:\n",
        "#  TRAIN = \"dataset_train\"\n",
        "#  VAL = \"dataset_val\"\n",
        "\n",
        "#train_coco = COCO(Paths.TRAIN_ANNOTATIONS)"
      ],
      "metadata": {
        "id": "JH_DedHcaGi5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(experiment_name=config.EXPERIMENT_NAME, ckpt_root_dir=config.CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "Mdu9EopEaYUQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = coco_detection_yolo_format_train(\n",
        "    dataset_params={\n",
        "        'data_dir': config.DATA_DIR,\n",
        "        'images_dir': config.TRAIN_IMAGES_DIR,\n",
        "        'labels_dir': config.TRAIN_LABELS_DIR,\n",
        "        'classes': config.CLASSES\n",
        "    },\n",
        "    dataloader_params=config.DATALOADER_PARAMS\n",
        ")\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': config.DATA_DIR,\n",
        "        'images_dir': config.VAL_IMAGES_DIR,\n",
        "        'labels_dir': config.VAL_LABELS_DIR,\n",
        "        'classes': config.CLASSES\n",
        "    },\n",
        "    dataloader_params=config.DATALOADER_PARAMS\n",
        ")\n",
        "\n",
        "test_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': config.DATA_DIR,\n",
        "        'images_dir': config.TEST_IMAGES_DIR,\n",
        "        'labels_dir': config.TEST_LABELS_DIR,\n",
        "        'classes': config.CLASSES\n",
        "    },\n",
        "    dataloader_params=config.DATALOADER_PARAMS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "Z3rWaXEPeo98",
        "outputId": "27362ee5-56b2-4967-98b9-ff4e649c2ef2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-04-29 20:12:48] WARNING - yolo_format_detection.py - 24119 images are note associated to any label file\n",
            "[2024-04-29 20:12:48] WARNING - yolo_format_detection.py - As a consequence, 0/24119 images and 0/0 label files will be used.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "_setup_data_source() should return the number of available samples but got 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0dca5c0e9b55>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_data = coco_detection_yolo_format_train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     dataset_params={\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'images_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_IMAGES_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'labels_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_LABELS_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/dataloaders/dataloaders.py\u001b[0m in \u001b[0;36mcoco_detection_yolo_format_train\u001b[0;34m(dataset_params, dataloader_params)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mregister_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOCO_DETECTION_YOLO_FORMAT_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcoco_detection_yolo_format_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     return get_data_loader(\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coco_detection_yolo_format_base_dataset_params\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mdataset_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYoloDarknetFormatDetectionDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/dataloaders/dataloaders.py\u001b[0m in \u001b[0;36mget_data_loader\u001b[0;34m(config_name, dataset_cls, train, dataset_params, dataloader_params)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mlocal_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwait_for_the_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset_params\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/detection_datasets/yolo_format_detection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, images_dir, labels_dir, classes, class_ids_to_ignore, ignore_invalid_labels, show_all_warnings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_fields\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_target_format\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXYXY_LABEL\u001b[0m  \u001b[0;31m# We convert yolo format (LABEL_CXCYWH) to Coco format (XYXY_LABEL) when loading the annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_all_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_all_warnings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/common/decorators/factory_decorator.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assign_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/detection_datasets/detection_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, original_target_format, max_num_samples, cache_annotations, input_dim, transforms, all_classes_list, class_inclusion_list, ignore_empty_annotations, target_fields, output_fields, verbose, show_all_warnings, cache, cache_dir)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mn_dataset_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_data_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_dataset_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn_dataset_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"_setup_data_source() should return the number of available samples but got {n_dataset_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_dataset_samples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmax_num_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_dataset_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: _setup_data_source() should return the number of available samples but got 0"
          ]
        }
      ]
    }
  ]
}